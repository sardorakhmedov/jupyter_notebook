{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a349dde-fb99-4e3d-95ee-2294ee95536c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.26\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.52      0.43        63\n",
      "           1       0.19      0.19      0.19        26\n",
      "           2       0.05      0.04      0.04        27\n",
      "           3       0.22      0.17      0.19        24\n",
      "           4       0.25      0.14      0.18        37\n",
      "           5       0.17      0.17      0.17        23\n",
      "\n",
      "    accuracy                           0.26       200\n",
      "   macro avg       0.21      0.20      0.20       200\n",
      "weighted avg       0.24      0.26      0.24       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "cities = ['Tokyo', 'Seoul', 'Berlin', 'London', 'Moscow', 'New York', 'Paris']\n",
    "vacation = ['beach', 'forest', 'urban', 'mountains', 'desert']\n",
    "transport = ['bike', 'scooter', 'train', 'plane', 'car', 'boat']\n",
    "target_cities = ['Bali', 'Kyoto', 'Rome', 'Hawaii', 'Sydney', 'Barcelona', 'Dubai']\n",
    "\n",
    "data = []\n",
    "for _ in range(1000):\n",
    "    salary = random.randint(30000, 150000)\n",
    "    city = random.choice(cities)\n",
    "    age = random.randint(20, 70)\n",
    "    vacation_prefer = random.choice(vacation)\n",
    "    transport_prefer = random.choice(transport)\n",
    "    target = random.choice(target_cities)\n",
    "    data.append([salary, city, age, vacation_prefer, transport_prefer, target])\n",
    "\n",
    "columns = ['salary', 'city', 'age', 'vacation_prefer', 'transport_prefer', 'target']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['city', 'vacation_prefer', 'transport_prefer', 'target'], drop_first=True)\n",
    "\n",
    "X = df.drop(columns=[col for col in df.columns if col.startswith('target_')])\n",
    "y = df[[col for col in df.columns if col.startswith('target_')]].values.argmax(axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d33c3a9-a5e4-4625-97e0-94a9b91f8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сетка параметров:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
      "Точность на тестовой выборке: 0.32\n",
      "\n",
      "Классификационный отчет:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48        63\n",
      "           1       0.00      0.00      0.00        26\n",
      "           2       0.00      0.00      0.00        27\n",
      "           3       0.00      0.00      0.00        24\n",
      "           4       0.00      0.00      0.00        37\n",
      "           5       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.32       200\n",
      "   macro avg       0.05      0.17      0.08       200\n",
      "weighted avg       0.10      0.32      0.15       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  def _prf_divide(\n",
      "C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  def _prf_divide(\n",
      "C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  def _prf_divide(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Определение сетки параметров\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  \n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "print(\"Сетка параметров:\")\n",
    "print(param_grid)\n",
    "\n",
    "# Настройка и обучение модели с помощью GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка точности\n",
    "y_pred_log = grid_search.predict(X_test)\n",
    "print(\"Точность на тестовой выборке: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "\n",
    "# Классификационный отчёт\n",
    "print(\"\\nКлассификационный отчет:\")\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d2dce4d-46ae-4d14-910d-27bc083c91aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели логистической регрессии = 0.29\n",
      "Confusion matrix:\n",
      "[[52  2  0  3  0  6]\n",
      " [22  0  0  2  0  2]\n",
      " [21  1  0  2  0  3]\n",
      " [17  1  0  2  0  4]\n",
      " [32  1  2  1  0  1]\n",
      " [17  1  0  1  0  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Настройка и обучение модели логистической регрессии\n",
    "log_reg = LogisticRegression(max_iter=20000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка точности\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Точность модели логистической регрессии = {accuracy_log:.2f}\")\n",
    "\n",
    "# Матрица ошибок\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, y_pred_log)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b61e3793-3a1f-4f1f-936a-9c6edd79277f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели: 0.17\n",
      "\n",
      "Классификационный отчет:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.25      0.25        63\n",
      "           1       0.17      0.15      0.16        26\n",
      "           2       0.15      0.15      0.15        27\n",
      "           3       0.08      0.12      0.10        24\n",
      "           4       0.16      0.11      0.13        37\n",
      "           5       0.13      0.13      0.13        23\n",
      "\n",
      "    accuracy                           0.17       200\n",
      "   macro avg       0.16      0.15      0.15       200\n",
      "weighted avg       0.17      0.17      0.17       200\n",
      "\n",
      "Точность на тестовой выборке: 0.32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Инициализация и обучение модели для отбора признаков\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Применение отбора признаков к данным\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Продолжение с обучением модели и предсказанием (например, с RandomForest)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Точность модели: {accuracy:.2f}\")\n",
    "print(\"\\nКлассификационный отчет:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Настройка и обучение модели с помощью GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Оценка точности на тестовом наборе\n",
    "print(\"Точность на тестовой выборке: {:.2f}\".format(grid_search.score(X_test_selected, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08143b72-0c5b-4044-b24c-e8ed4247fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели логистической регрессии = 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Настройка и обучение модели логистической регрессии\n",
    "log_reg = LogisticRegression(max_iter=20000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка точности\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Точность модели логистической регрессии = {accuracy_log:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc101393-5cc7-41a0-8a4e-582b9d43a9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Создание полиномиальных признаков (только взаимодействия, степень 2)\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Настройка и обучение модели с помощью GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_poly, y_train)\n",
    "\n",
    "# Оценка точности на тестовом наборе\n",
    "print(\"Точность на тестовой выборке: {:.2f}\".format(grid_search.score(X_test_poly, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0952a70-87d2-4a67-a118-248813696cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели логистической регрессии = 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Настройка и обучение модели логистической регрессии\n",
    "log_reg = LogisticRegression(max_iter=20000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка точности\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Точность модели логистической регрессии = {accuracy_log:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38e87cae-7abe-48c7-aa70-dfd467e34a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Применение PCA для снижения размерности (10 компонент)\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Настройка и обучение модели с помощью GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Оценка точности на тестовом наборе\n",
    "print(\"Точность на тестовой выборке: {:.2f}\".format(grid_search.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9727687b-3857-408f-95b3-bddb82c7517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели логистической регрессии = 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Настройка и обучение модели логистической регрессии\n",
    "log_reg = LogisticRegression(max_iter=20000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и оценка точности\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(f\"Точность модели логистической регрессии = {accuracy_log:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e56989d-09d9-4ba5-8ce8-47181574c6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность на тестовой выборке: 0.32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Стандартизация данных (приведение к нулевому среднему и единичному стандартному отклонению)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Настройка и обучение модели с помощью GridSearchCV\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Оценка точности на тестовом наборе\n",
    "print(\"Точность на тестовой выборке: {:.2f}\".format(grid_search.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c918bf49-b966-42d8-a7bf-5504799afc8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'validate_data' from 'sklearn.utils.validation' (C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\imblearn\\over_sampling\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansSMOTE\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVMSMOTE, BorderlineSMOTE\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVMSMOTE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m ]\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\cluster.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MiniBatchKMeans\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pairwise_distances\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\cluster\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Popular unsupervised clustering algorithms.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_affinity_propagation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AffinityPropagation, affinity_propagation\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_agglomerative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     AgglomerativeClustering,\n\u001b[0;32m      9\u001b[0m     FeatureAgglomeration,\n\u001b[0;32m     10\u001b[0m     linkage_tree,\n\u001b[0;32m     11\u001b[0m     ward_tree,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bicluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpectralBiclustering, SpectralCoclustering\n",
      "File \u001b[1;32m~\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, StrOptions, validate_params\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted, validate_data\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_equal_similarities_and_preferences\u001b[39m(S, preference):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_equal_preferences\u001b[39m():\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'validate_data' from 'sklearn.utils.validation' (C:\\Users\\default.DESKTOP-TEHK88J\\PycharmProjects\\pythonProject6\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Создание пайплайна с RandomOverSampler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Стандартизация данных\n",
    "    ('ros', RandomOverSampler(random_state=42)),  # Балансировка классов с использованием RandomOverSampler\n",
    "    ('xgb', XGBClassifier(\n",
    "        random_state=42, \n",
    "        eval_metric='mlogloss', \n",
    "        n_estimators=200, \n",
    "        max_depth=5, \n",
    "        learning_rate=0.1\n",
    "    ))  # Классификатор XGBoost\n",
    "])\n",
    "\n",
    "# Обучение модели\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания на обучающих и тестовых данных\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Оценка точности на обучающих данных\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Точность на обучающих данных: {train_accuracy:.2f}\")\n",
    "\n",
    "# Оценка точности на тестовых данных\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Точность на тестовых данных: {test_accuracy:.2f}\")\n",
    "\n",
    "# Вывод матрицы ошибок и классификационного отчета\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d6096-4666-4acf-ab69-5ee9ffa6a96e",
   "metadata": {},
   "source": [
    "Эксперименты с различными методами машинного обучения, включая логистическую регрессию, случайный лес и решетчатый поиск, показали, что точность моделей остаётся неизменной, независимо от настройки гиперпараметров и методов балансировки данных. Это связано с тем, что текущий набор данных, созданный случайным образом, не содержит реальных взаимосвязей между признаками и целевой переменной (местом отдыха). В реальной задаче, например, такие признаки, как уровень зарплаты, могли бы указывать на выбор более дорогого места отдыха, что позволило бы моделям выявлять закономерности и улучшать предсказания. Однако в данном случае смысловые зависимости отсутствуют, что ограничивает точность модели. Таким образом, улучшить точность можно только путём изменения данных, чтобы они отражали реальные закономерности и взаимосвязи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
